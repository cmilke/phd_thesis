\chapter{Event Reconstruction and Selection}

    Oh god how do I even start with this crap. These two are so tightly linked and there's no obvious way to speparate them AHHHHHH.
    
%    Once a bunch crossing event has cleared the Level 1 Trigger system, the process of event reconstruction begins.
%    An event in ATLAS is, initially, nothing but a collection of electrical signals emitted from the various detectors.
%    Event reconstruction is the process wherein detector readings are aggregated together into meaningful patterns,
%        which are interpreted as physical objects and processes.
%


\section{Object Classification}

    Ok let's just get the basic objects contructed first, since nothing else (triggers, later reconstruction, final selection)
        make sense until I have them.

    This entails ... what? For VBF 4b I think we have:


    %    I should have an image for this in some way %TODO
    \subsection{Tracks}
        Intro about tracks being the first things we see because they're assembled from the inner detector or something.
        Also I should probably explain what a track is...
        Might need to explain helix parameters as well

        %Clusterization
        The first step to producing a track is the process of clusterization.
        Ionizing particles often deposit energy across several adjacent pixels on a given layer.
        A \textit{connected component analysis} algorithm is used to group pixels together. 
        Based on the pattern of energy distribution in these groups,
            a \textit{space-point} is created indicating the estimated position at which a particle crossed the detector.
        Several space-points can be assigned to the same pixel cluster,
            if the energy deposition pattern suggests multiple particles traversed the same location.

        %Combinatorial track finding
        Initial guesses at tracks, called track seeds, are formed by assembling all realistic combinations of three space-points.
        The track seeds are assigned helix parameters by assuming they travel through a uniform magnetic field,
            allowing immediate estimates of the tracks' momentum.
        These seeds are expanded into \textit{track candidates},
            by including more space-points across additional detectors in the ID using a Kalman filter.

        %Ambiguity solving; NN clustering; Track fit
        A number of criteria are then used to reject poor-quality tracks, as well as to assign scores to all remaining track candidates.
        The scores are then used to resolve ambiguities where multiple tracks are assigned to the same space-points,
            with preference given to higher-scoring candidates.
        Neural networks are used to assist in some ambiguity solving situations,
            as well as to help identify clusters with multiple valid tracks.
        Once ambiguities have been resolved and all malformed track candidates removed,
            the remaining tracks are refit using all available information at high-resolution.
        \cite{atlas_track_reco_performance}

    \subsection{Jets}
        Jets are an algorithm.
        Specifically, the anti-$k_t$ algorithm, with $\Delta R = 0.4$.
        Something about topological-clusters (topo-clusters).
        \cite{anti_kt}
        Something about assuming hard-scatter jets come from the primary vertex.
        Also explain what a primary vertex is.
        FYI, a primary vertex is a "reconstructed vertex with at least two associated tracks, and the largest sum of squared track momentum".

        Jets created using only calorimeter-based topological-clusters (at the electromagnetic scale [what does this mean??]) %TODO?
            are reffered to as \textit{EMtopo Jets}.
        The jets for this analysis use a more advanced type of jet however, called \textit{PFlow Jets},
            which are constructed using information from both the calorimeters and the inner trackers.
        And now I need to explain how pflow works...
        \cite{pflow}
        \cite{jet_energy_scale13TeV}

    \subsection{Flavor Tagging}
        b-jets used for higgs, (I should justify this with the high branching ratio of H->b,bbar)
        light jets used for VBF IS quarks.
        \cite{bjet_id_and_performance}

    \subsection{Online VS Offline Reconstruction}
        I should explain how online and offline reco differs.
        I should also describe the mv2 reweighting procedure here.

    \subsection{Other?}
        ... is that it? I'll look around to see if there's anything else.



    %Reconstruction is performed for an event twice.
    %It is first done rapidly, using coarse measurments and calculations,
    %    for the purpose of allowing the aforementioned HLT to trigger events for readout.
    %These events which pass the trigger are passed off to a massive global computer cluster reffered to as the GRID.
    %No longer bound by the stringent time contrainsts of the ``online'' running environment,
    %    the GRID is able to devote vast amounts of time and computing power to a second, 
    %    more comprehensive, reconstruction of each event.
    %For both the ``online'' (HLT) and ``offline'' (GRID) environments, event reconstruction is carried out by the same suite of software,
    %    called \textit{Athena}.
    





\section{HH4b VBF Analysis}
    
    I think I'm just going to do everything else here? It's weird, because I'm going backwards to triggers,
        and then forward to the final analysis stuff. But at least I have all the complicated object algorithms and stuff listed I guess?

    %Truthfully, reconstruction and selection are not distinct stages of the analysis, but rather are interwoven with each other.
    %The first step of selection really occured before any signficant reconstruction had even taken place, in the L1 Trigger system.
    %Yet the final stage of event reconstruction -- the reconstruction of the di-Higgs system --
    %    will be performed \textit{after} almost every other stage of selection.

    Triggers used in this analysis and why (do we have any plots showing why we use these triggers?)

    Trigger bucketing strategy?

    I need to discuss the kinematics of VBF and 4b in order to justify the ->

    kinematic cuts
        basic jet multiplicity reqs,
        4b-tagged, central
        2 non-btagged jets with min-mjj for VBF

    Then there's the minDR pairing of b's to reconstruct HH

    Then cut on dihiggs and full system kinematics

    Then make sure the higgss fall within the "signal region" (their individual masses are approximately 125 GeV)

    Pretty sure that's it?



%...and how we wittle the abundance of events down to a manageable subset.
%If I stick to this format, there's still a bit of event reconstruction done here.
%
%HH4b Resolved Reco and Selection (literally just go through resolved recon...).
%    Final stage is the signal region selection
